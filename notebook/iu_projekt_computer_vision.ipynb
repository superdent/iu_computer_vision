{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5f5c540760d8dee",
   "metadata": {},
   "source": [
    "# Verkehrszeichenerkennung in Dashcam-Videos\n",
    "Dieses Notebook lädt ein Eingangs-Video, erkennt Verkehrszeichen mit einem vortrainierten YOLOv5-Modell und erstellt ein Ausgangsvideo mit eingeblendeten Schildernamen.\n",
    "\n",
    "## Schritte:\n",
    "1. Imports und Setup\n",
    "2. Video laden\n",
    "3. Modell laden\n",
    "4. Erkennung und Untertitelung\n",
    "5. Ausgabevideo speichern\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3c9d2cb4ce48dd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22632c4f",
   "metadata": {},
   "source": [
    "#import os\n",
    "#os.system(\"pip freeze | xargs pip uninstall -y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f824a1ac7f893854",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T20:31:06.377133Z",
     "start_time": "2025-07-03T20:31:00.403750Z"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements_notebook.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f020dd3b06080fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca790df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('../yolo_training/yolo_training.yaml', 'r') as f:\n",
    "    data = yaml.safe_load(f)\n",
    "\n",
    "class_names = data['names']\n",
    "print(f\"{len(class_names)} Klassen geladen:\")\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ea03e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='best.pt', force_reload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdc4208daccd637",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T20:29:25.315311Z",
     "start_time": "2025-07-03T20:29:25.278973Z"
    }
   },
   "outputs": [],
   "source": [
    "video_path = 'input_videos/cv_regen_1_niedrige_qualität.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Fehler: Video konnte nicht geöffnet werden.\")\n",
    "else:\n",
    "    print(\"Video erfolgreich geöffnet.\")\n",
    "\n",
    "ret, frame = cap.read()\n",
    "if not ret:\n",
    "    print(\"Kein Frame gelesen.\")\n",
    "else:\n",
    "    print(\"Frame gelesen:\", frame.shape)\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(\"Video-FPS:\", fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d60422",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img_rgb)\n",
    "ax.axis('off')\n",
    "display(fig)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72908c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT-VIDEO 640 x 640\n",
    "\n",
    "# Schwellenwerte\n",
    "CONF_THRESHOLD = 0.3\n",
    "MAX_BOX_AREA_RATIO = 0.08\n",
    "MAX_FRAMES = 999999\n",
    "FRAME_START = 0\n",
    "\n",
    "# Frame-Parameter\n",
    "FRAME_H = 720\n",
    "FRAME_W = 1280\n",
    "\n",
    "# Rescaling der Frames, so dass es zum Modell passt\n",
    "TARGET_W = 640\n",
    "TARGET_H = 360\n",
    "SCALE = 2\n",
    "PADDING_V = 140\n",
    "PADDING_H = 0\n",
    "\n",
    "# Modellparameter\n",
    "MODEL_INPUT_SIZE = 640\n",
    "\n",
    "# Abgeleitete Werte\n",
    "MAX_BOX_AREA = MAX_BOX_AREA_RATIO * FRAME_W * FRAME_H\n",
    "\n",
    "# Initialisierung\n",
    "frame_count = FRAME_START\n",
    "\n",
    "cap.release()\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, frame_count)\n",
    "\n",
    "output_path = 'output_videos/ergebnis_640.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_frame_size = (MODEL_INPUT_SIZE, MODEL_INPUT_SIZE)\n",
    "writer = cv2.VideoWriter(output_path, fourcc, fps, output_frame_size)\n",
    "print(\"VideoWriter initialisiert.\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    resized = cv2.resize(frame_rgb, (TARGET_W, TARGET_H))\n",
    "    img_resized = cv2.copyMakeBorder(resized, PADDING_V, PADDING_V, PADDING_H, PADDING_H, cv2.BORDER_CONSTANT, value=(114, 114, 114))\n",
    "\n",
    "    input_tensor = torch.from_numpy(img_resized).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model(input_tensor)[0].cpu().tolist()\n",
    "\n",
    "    for pred in preds:\n",
    "        # print(f\"pred: {pred}\")\n",
    "        cx, cy, w, h = pred[0], pred[1], pred[2], pred[3]\n",
    "        objectness = pred[4]\n",
    "        class_scores = pred[5:]\n",
    "\n",
    "        max_score = max(class_scores)\n",
    "        conf = objectness * max_score\n",
    "        if conf < CONF_THRESHOLD:\n",
    "            continue\n",
    "\n",
    "        cls_index = class_scores.index(max_score)\n",
    "        print(f\"conf={conf:.4f} für Klasse {cls_index}\")\n",
    "\n",
    "        x1 = int(cx - w / 2)\n",
    "        y1 = int(cy - h / 2)\n",
    "        x2 = int(cx + w / 2)\n",
    "        y2 = int(cy + h / 2)\n",
    "\n",
    "        x1 = max(0, x1)\n",
    "        y1 = max(0, y1)\n",
    "        x2 = min(MODEL_INPUT_SIZE, x2)\n",
    "        y2 = min(MODEL_INPUT_SIZE, y2)\n",
    "\n",
    "        print(f\"Rechteck: {x1},{y1} -> {x2},{y2}\")\n",
    "        box_area = (x2 - x1) * (y2 - y1)\n",
    "\n",
    "        label = class_names[cls_index]\n",
    "        cv2.rectangle(img_resized, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(img_resized, label, (10, MODEL_INPUT_SIZE - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        print(f\"Gezeichnet: {label}\")\n",
    "\n",
    "    writer.write(cv2.cvtColor(img_resized, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count % 100 == 0:\n",
    "        print(f\"{frame_count} Frames verarbeitet.\")\n",
    "\n",
    "    if frame_count >= MAX_FRAMES:\n",
    "        print(f\"Es wurden {MAX_FRAMES} Frames verarbeitet und die Verarbeitung wird beendet.\")\n",
    "        break     \n",
    "\n",
    "cap.release()\n",
    "writer.release()\n",
    "print(\"Fertig.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710f2047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT-VIDEO 1280 x 720\n",
    "\n",
    "# Schwellenwerte\n",
    "CONF_THRESHOLD = 0.6\n",
    "MAX_BOX_AREA_RATIO = 0.08\n",
    "MAX_FRAMES = 100\n",
    "FRAME_START = 0\n",
    "\n",
    "# Frame-Parameter\n",
    "FRAME_H = 720\n",
    "FRAME_W = 1280\n",
    "\n",
    "# Rescaling der Frames, so dass es zum Modell passt\n",
    "TARGET_W = 640\n",
    "TARGET_H = 360\n",
    "SCALE = 2\n",
    "PADDING_V = 140\n",
    "PADDING_H = 0\n",
    "\n",
    "# Modellparameter\n",
    "MODEL_INPUT_SIZE = 640\n",
    "\n",
    "# Abgeleitete Werte\n",
    "MAX_BOX_AREA = MAX_BOX_AREA_RATIO * FRAME_W * FRAME_H\n",
    "\n",
    "# Initialisierung\n",
    "frame_count = FRAME_START\n",
    "\n",
    "cap.release()\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, frame_count)\n",
    "\n",
    "output_path = 'output_videos/ergebnis.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_frame_size = (FRAME_W, FRAME_H)\n",
    "\n",
    "writer = cv2.VideoWriter(output_path, fourcc, fps, output_frame_size)\n",
    "print(\"VideoWriter initialisiert.\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    resized = cv2.resize(frame_rgb, (TARGET_W, TARGET_H))\n",
    "    img_resized = cv2.copyMakeBorder(resized, PADDING_V, PADDING_V, PADDING_H, PADDING_H, cv2.BORDER_CONSTANT, value=(114, 114, 114))\n",
    "\n",
    "    input_tensor = torch.from_numpy(img_resized).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model(input_tensor)[0].cpu().tolist()\n",
    "\n",
    "    for pred in preds:\n",
    "        # print(f\"pred: {pred}\")\n",
    "        cx, cy, w, h = pred[0], pred[1], pred[2], pred[3]\n",
    "        objectness = pred[4]\n",
    "        class_scores = pred[5:]\n",
    "\n",
    "        max_score = max(class_scores)\n",
    "        conf = objectness * max_score\n",
    "        if conf < CONF_THRESHOLD:\n",
    "            continue\n",
    "\n",
    "        cls_index = class_scores.index(max_score)\n",
    "        print(f\"conf={conf:.4f} für Klasse {cls_index}\")\n",
    "\n",
    "        x1 = cx - w / 2\n",
    "        y1 = cy - h / 2\n",
    "        x2 = cx + w / 2\n",
    "        y2 = cy + h / 2\n",
    "\n",
    "        draw_x1 = int(x1 * SCALE)\n",
    "        draw_y1 = int((y1 - PADDING_V) * SCALE)\n",
    "        draw_x2 = int(x2 * SCALE)\n",
    "        draw_y2 = int((y2 - PADDING_V) * SCALE)\n",
    "\n",
    "        draw_x1 = max(0, draw_x1)\n",
    "        draw_y1 = max(0, draw_y1)\n",
    "        draw_x2 = min(FRAME_W, draw_x2)\n",
    "        draw_y2 = min(FRAME_H, draw_y2)\n",
    "        print(f\"Rechteck: {draw_x1},{draw_y1} -> {draw_x2},{draw_y2}\")\n",
    "\n",
    "        box_area = (draw_x2 - draw_x1) * (draw_y2 - draw_y1)\n",
    "        #if box_area > MAX_BOX_AREA:\n",
    "        #    print(f\"Übersprungen wegen Größe: {box_area}px\")\n",
    "        #    continue\n",
    "\n",
    "        label = class_names[cls_index]\n",
    "        cv2.rectangle(frame, (draw_x1, draw_y1), (draw_x2, draw_y2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, label, (10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        print(f\"Gezeichnet: {label}\")\n",
    "\n",
    "    writer.write(frame)\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count % 100 == 0:\n",
    "        print(f\"{frame_count} Frames verarbeitet.\")\n",
    "\n",
    "    if frame_count >= MAX_FRAMES:\n",
    "        print(f\"Es wurden {MAX_FRAMES} Frames verarbeitet und die Verarbeitung wird beendet.\")\n",
    "        break     \n",
    "\n",
    "cap.release()\n",
    "writer.release()\n",
    "print(\"Fertig.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
